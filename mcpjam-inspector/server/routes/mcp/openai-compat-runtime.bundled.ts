// This file is auto-generated by scripts/bundle-openai-compat-runtime.js
// Do not edit directly - modify server/routes/mcp/openai-compat-runtime.ts instead

export const OPENAI_COMPAT_RUNTIME_SCRIPT = "\"use strict\";\n(() => {\n  // server/routes/mcp/openai-compat-runtime.ts\n  (function bootstrap() {\n    if (window.openai) return;\n    const CONFIG_ID = \"openai-compat-config\";\n    const readConfig = () => {\n      try {\n        const el = document.getElementById(CONFIG_ID);\n        if (!el) {\n          console.warn(\"[OpenAI Compat] Missing config element #\" + CONFIG_ID);\n          return null;\n        }\n        return JSON.parse(el.textContent || \"{}\");\n      } catch (err) {\n        console.error(\"[OpenAI Compat] Failed to parse config\", err);\n        return null;\n      }\n    };\n    const config = readConfig();\n    if (!config) return;\n    const {\n      toolId,\n      toolName,\n      toolInput,\n      toolOutput,\n      theme,\n      viewMode,\n      viewParams\n    } = config;\n    let callId = 0;\n    const pendingCalls = /* @__PURE__ */ new Map();\n    const CALL_TIMEOUT_MS = 3e4;\n    const sendRequest = (method, params) => {\n      const id = ++callId;\n      window.parent.postMessage({ jsonrpc: \"2.0\", id, method, params }, \"*\");\n      return { id };\n    };\n    const sendNotification = (method, params) => {\n      window.parent.postMessage(\n        { jsonrpc: \"2.0\", method, params: params ?? {} },\n        \"*\"\n      );\n    };\n    const postHeight = /* @__PURE__ */ (() => {\n      let lastHeight = 0;\n      return (height) => {\n        const rounded = Math.round(height);\n        if (rounded <= 0 || rounded === lastHeight) return;\n        lastHeight = rounded;\n        sendNotification(\"ui/notifications/size-changed\", {\n          height: rounded\n        });\n      };\n    })();\n    const measureAndNotifyHeight = () => {\n      try {\n        let contentHeight = 0;\n        if (document.body) {\n          const children = document.body.children;\n          for (let i = 0; i < children.length; i++) {\n            const child = children[i];\n            if (child.tagName === \"SCRIPT\" || child.tagName === \"STYLE\") continue;\n            const rect = child.getBoundingClientRect();\n            const bottom = rect.top + rect.height + window.scrollY;\n            contentHeight = Math.max(contentHeight, bottom);\n          }\n          const bodyStyle = window.getComputedStyle(document.body);\n          contentHeight += parseFloat(bodyStyle.marginBottom) || 0;\n          contentHeight += parseFloat(bodyStyle.paddingBottom) || 0;\n        }\n        if (contentHeight <= 0) {\n          const docEl = document.documentElement;\n          contentHeight = Math.max(\n            docEl ? docEl.scrollHeight : 0,\n            document.body ? document.body.scrollHeight : 0\n          );\n        }\n        postHeight(Math.ceil(contentHeight));\n      } catch {\n      }\n    };\n    const setupAutoResize = () => {\n      let scheduled = false;\n      const scheduleMeasure = () => {\n        if (scheduled) return;\n        scheduled = true;\n        requestAnimationFrame(() => {\n          scheduled = false;\n          measureAndNotifyHeight();\n        });\n      };\n      scheduleMeasure();\n      if (typeof ResizeObserver !== \"undefined\") {\n        const ro = new ResizeObserver(scheduleMeasure);\n        ro.observe(document.documentElement);\n        if (document.body) ro.observe(document.body);\n      } else {\n        window.addEventListener(\"resize\", scheduleMeasure);\n      }\n      window.addEventListener(\"load\", () => {\n        requestAnimationFrame(measureAndNotifyHeight);\n      });\n    };\n    const openaiAPI = {\n      toolInput: toolInput ?? {},\n      toolOutput: toolOutput ?? null,\n      theme: theme ?? \"dark\",\n      displayMode: \"inline\",\n      viewMode: viewMode ?? \"inline\",\n      viewParams: viewParams ?? {},\n      widgetState: null,\n      /**\n       * Call an MCP tool by name. Returns a Promise resolved when the\n       * host sends back the JSON-RPC response with the matching id.\n       */\n      callTool(name, args = {}) {\n        const { id } = sendRequest(\"tools/call\", {\n          name,\n          arguments: args,\n          _meta: {}\n        });\n        return new Promise((resolve, reject) => {\n          pendingCalls.set(id, { resolve, reject });\n          setTimeout(() => {\n            if (pendingCalls.has(id)) {\n              pendingCalls.delete(id);\n              reject(new Error(\"Tool call timeout\"));\n            }\n          }, CALL_TIMEOUT_MS);\n        });\n      },\n      /**\n       * Send a follow-up message to the host chat.\n       * Uses sendRequest (not notification) because ui/message is a JSON-RPC\n       * request in the MCP Apps spec â€” the AppBridge only dispatches requests\n       * (messages with an id) to its onmessage handler.\n       */\n      sendFollowUpMessage(opts) {\n        const prompt = typeof opts === \"string\" ? opts : opts?.prompt ?? \"\";\n        sendRequest(\"ui/message\", {\n          role: \"user\",\n          content: [{ type: \"text\", text: prompt }]\n        });\n      },\n      /**\n       * Alias for sendFollowUpMessage (ChatGPT compat).\n       */\n      sendFollowupTurn(message) {\n        this.sendFollowUpMessage(message);\n      },\n      /**\n       * Notify the host of the widget's intrinsic height.\n       */\n      notifyIntrinsicHeight(height) {\n        const n = Number(height);\n        if (Number.isFinite(n) && n > 0) postHeight(n);\n      },\n      /**\n       * Open an external URL in a new tab.\n       * ui/open-link is a request in the spec; param is `url` (not `href`).\n       */\n      openExternal(options) {\n        const href = typeof options === \"string\" ? options : options?.href;\n        if (!href) throw new Error(\"href is required for openExternal\");\n        sendRequest(\"ui/open-link\", { url: href });\n      },\n      /**\n       * Request a display mode change (inline, fullscreen, pip).\n       * ui/request-display-mode is a request in the spec.\n       */\n      requestDisplayMode(options = {}) {\n        const mode = options.mode || \"inline\";\n        this.displayMode = mode;\n        sendRequest(\"ui/request-display-mode\", { mode });\n        return { mode };\n      },\n      /**\n       * Store arbitrary widget state for persistence.\n       * Maps to ui/update-model-context which is a request expecting\n       * { content?: ContentBlock[], structuredContent?: Record }.\n       */\n      setWidgetState(state) {\n        this.widgetState = state;\n        sendRequest(\"ui/update-model-context\", {\n          structuredContent: typeof state === \"object\" && state !== null ? state : { value: state }\n        });\n      },\n      /**\n       * Request a modal to be opened (ChatGPT-specific, notification).\n       */\n      requestModal(options) {\n        const opts = options ?? {};\n        sendNotification(\"openai/requestModal\", {\n          title: opts.title,\n          params: opts.params,\n          anchor: opts.anchor,\n          template: opts.template\n        });\n      },\n      /**\n       * Request the widget to be closed (ChatGPT-specific, notification).\n       */\n      requestClose() {\n        sendNotification(\"openai/requestClose\", { toolId });\n      }\n    };\n    window.addEventListener(\"message\", (event) => {\n      const data = event.data;\n      if (!data || data.jsonrpc !== \"2.0\") return;\n      if (data.id != null && (data.result !== void 0 || data.error !== void 0)) {\n        const pending = pendingCalls.get(data.id);\n        if (pending) {\n          pendingCalls.delete(data.id);\n          if (data.error) {\n            pending.reject(\n              new Error(\n                typeof data.error === \"string\" ? data.error : data.error?.message ?? \"Unknown error\"\n              )\n            );\n          } else {\n            pending.resolve(data.result);\n          }\n        }\n        return;\n      }\n      if (data.method) {\n        const params = data.params ?? {};\n        switch (data.method) {\n          // MCP Apps bridge notification names (SEP-1865)\n          case \"ui/notifications/tool-input\":\n            openaiAPI.toolInput = params.arguments ?? params;\n            break;\n          case \"ui/notifications/tool-input-partial\":\n            openaiAPI.toolInput = params.arguments ?? params;\n            break;\n          case \"ui/notifications/tool-result\":\n            openaiAPI.toolOutput = params;\n            break;\n          case \"ui/notifications/tool-cancelled\":\n            break;\n          case \"ui/notifications/host-context-changed\":\n            if (params.theme) openaiAPI.theme = params.theme;\n            if (params.displayMode) openaiAPI.displayMode = params.displayMode;\n            break;\n        }\n      }\n    });\n    const PROTOCOL_VERSION = \"2026-01-26\";\n    const initId = ++callId;\n    window.parent.postMessage(\n      {\n        jsonrpc: \"2.0\",\n        id: initId,\n        method: \"ui/initialize\",\n        params: {\n          appInfo: { name: \"openai-compat\", version: \"1.0.0\" },\n          appCapabilities: {},\n          protocolVersion: PROTOCOL_VERSION\n        }\n      },\n      \"*\"\n    );\n    pendingCalls.set(initId, {\n      resolve: (result) => {\n        const res = result;\n        if (res?.hostContext) {\n          const ctx = res.hostContext;\n          if (ctx.theme && typeof ctx.theme === \"string\")\n            openaiAPI.theme = ctx.theme;\n          if (ctx.displayMode && typeof ctx.displayMode === \"string\")\n            openaiAPI.displayMode = ctx.displayMode;\n        }\n        sendNotification(\"ui/notifications/initialized\", {});\n      },\n      reject: () => {\n        sendNotification(\"ui/notifications/initialized\", {});\n      }\n    });\n    Object.defineProperty(window, \"openai\", {\n      value: openaiAPI,\n      writable: false,\n      configurable: false,\n      enumerable: true\n    });\n    setupAutoResize();\n  })();\n})();\n";
